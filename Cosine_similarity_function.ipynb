{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b74633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c575ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "from tslearn.metrics import dtw\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b20757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_sim(vector_months_regions):\n",
    "    \"\"\"\"\n",
    "    Calculate cosine similarity between consecutive months for each city.\n",
    "    Works across multiple years without resetting at year boundaries.\n",
    "    \n",
    "    Parameters:\n",
    "        vector_months_regions: np.array with shape (number_region, 2, total_timesteps)\n",
    "        number_region: int, number of cities\n",
    "        total_timesteps: int, total number of months across years\n",
    "    \n",
    "    Returns:\n",
    "        vectors_cosine_sim: np.array with shape (number_region, total_timesteps-1)\n",
    "    \"\"\"\n",
    "    if vector_months_regions.ndim != 3 or vector_months_regions.shape[1] != 2:\n",
    "        raise ValueError(f\"Input vector_mc must have shape (n_mc, 2, total_timesteps), but got {vector_months_regions.shape}\")\n",
    "        \n",
    "    number_region, _, total_timesteps = vector_months_regions.shape #number_region, total time steps here is number of months\n",
    "    if total_timesteps < 2:\n",
    "        return np.empty((n_mc, 0), dtype=float)\n",
    "        \n",
    "    vectors_cosine_sim = np.full((number_region, total_timesteps - 1), 0, dtype=float)\n",
    "\n",
    "    for i in range(number_region):  # Iterate over cities\n",
    "        for w in range(total_timesteps - 1):  # Iterate over months\n",
    "            v1_x, v1_y = vector_months_regions[i, 0, w], vector_months_regions[i, 1, w]\n",
    "            v2_x, v2_y = vector_months_regions[i, 0, w + 1], vector_months_regions[i, 1, w + 1]\n",
    "\n",
    "            f_i = math.sqrt(v1_x**2 + v1_y**2)\n",
    "            f_j = math.sqrt(v2_x**2 + v2_y**2)\n",
    "            dot_p = (v1_x * v2_x) + (v1_y * v2_y)\n",
    "\n",
    "            if f_i * f_j != 0:\n",
    "                cosine_value = dot_p / (f_i * f_j)\n",
    "                vectors_cosine_sim[i, w] = cosine_value  # Store result\n",
    "            \n",
    "    return vectors_cosine_sim\n",
    "\n",
    "\n",
    "def calculate_dtw_distance_matrix(time_series_data):\n",
    "    \"\"\"Computes ta pairwise Dynamic Time Warping (DTW) distance matrix between time series.\n",
    "        Each row is a time series for one unit (e.g. city, region)\n",
    "        Columns are time points (consecutive months)\"\"\"\n",
    "    \n",
    "    if time_series_data.ndim != 2:\n",
    "        raise ValueError(f\"Input time_series_data must have shape (n_series, n_timesteps), but got {time_series_data.shape}\")\n",
    "\n",
    "    n_series = time_series_data.shape[0]\n",
    "    distance_matrix = np.zeros((n_series, n_series))\n",
    "\n",
    "    #Loops through all unique pairs of time series\n",
    "    for i in range(n_series):\n",
    "        for j in range(i + 1, n_series):\n",
    "            ts_i = np.ascontiguousarray(time_series_data[i], dtype=np.float64)\n",
    "            ts_j = np.ascontiguousarray(time_series_data[j], dtype=np.float64)\n",
    "            dist = dtw(ts_i, ts_j)\n",
    "            distance_matrix[i, j] = dist\n",
    "            distance_matrix[j, i] = dist\n",
    "    return distance_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kmedoids_clustering(distance_matrix, n_clusters):\n",
    "    \"\"\"Clusters regions using the K-Medoids algorithm based on a precomputed distance matrix\"\"\"\n",
    "    if distance_matrix.shape[0] != distance_matrix.shape[1]:\n",
    "        raise ValueError(f\"Distance matrix must be square, but got shape {distance_matrix.shape}\")\n",
    "    if n_clusters > distance_matrix.shape[0]:\n",
    "        raise ValueError(f\"Number of clusters ({n_clusters}) cannot be greater than the number of data points ({distance_matrix.shape[0]})\")\n",
    "\n",
    "    kmedoids = KMedoids(n_clusters=n_clusters, metric=\"precomputed\", random_state=42, init='k-medoids++', max_iter=300)\n",
    "    clusters = kmedoids.fit_predict(distance_matrix) #assigns a cluster label to each region.\n",
    "    return clusters, kmedoids\n",
    "\n",
    "def calculate_cluster_means(time_series_data, clusters):\n",
    "    \"\"\"Calculates the average cosine similarity values for each cluster\"\"\"\n",
    "    if time_series_data.ndim != 2 or clusters.ndim != 1 or time_series_data.shape[0] != len(clusters):\n",
    "        # Raise error instead of returning None\n",
    "        raise ValueError(\"Invalid input shapes for calculate_cluster_means.\")\n",
    "        \n",
    "    number_regions, n_timesteps = time_series_data.shape\n",
    "        \n",
    "    n_clusters = len(set(clusters)) \n",
    "    \n",
    "    cluster_means = np.zeros((n_clusters, n_timesteps))\n",
    "    cluster_counts = np.zeros(n_clusters)\n",
    "\n",
    "    for i in range(number_regions):\n",
    "        cluster_label = clusters[i]\n",
    "        cluster_means[cluster_label] += time_series_data[i]\n",
    "        cluster_counts[cluster_label] += 1\n",
    "        \n",
    "    # Normalize to get average trends\n",
    "    for c in range(n_clusters):\n",
    "        if cluster_counts[c] > 0:\n",
    "            cluster_means[c] /= cluster_counts[c]\n",
    "\n",
    "    return cluster_means[:n_clusters]\n",
    "\n",
    "def sinusoidal(t, A, B, C, D):\n",
    "    \"\"\"Sinusoidal function for curve fitting.\"\"\"\n",
    "    return A * np.sin(B * t + C) + D\n",
    "\n",
    "def fit_sinusoidal(x, y):\n",
    "    \"\"\"Fits a sinusoidal function to time-series data.\"\"\"\n",
    "    \n",
    "    amplitude_guess = np.ptp(y) / 2 if np.ptp(y) > 1e-9 else 0.1 # ptp = peak-to-peak range\n",
    "    mean_guess = np.mean(y)\n",
    "    guess = [amplitude_guess, 2 * np.pi / 12, 0, mean_guess]\n",
    "    \n",
    "    # Fit curve using non-linear least squares\n",
    "    popt, pcov = curve_fit(sinusoidal, x, y, p0=guess, maxfev=10000)\n",
    "    # Optionally check pcov for finite values if needed, but no print/try\n",
    "    return popt\n",
    "\n",
    "\n",
    "def plot_combined_cluster_trends(cluster_means, cluster_colors, save_path_svg=None, savgol_window=7, savgol_order=3):\n",
    "    \"\"\"Plots all cluster trends together with fits. \"\"\"\n",
    "\n",
    "    n_clusters, n_timesteps = cluster_means.shape\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    months_axis = np.arange(1, n_timesteps + 1)\n",
    "\n",
    "    for c in range(n_clusters):\n",
    "        avg_trend = cluster_means[c]\n",
    "        cluster_label_key = f\"cluster {c+1}\"\n",
    "        plot_color = cluster_colors.get(c, 'gray')\n",
    "\n",
    "        smooth_trend = avg_trend\n",
    "        if savgol_window < len(avg_trend) and savgol_window % 2 != 0:\n",
    "            # savgol_filter will raise ValueError on failure\n",
    "            smooth_trend = savgol_filter(avg_trend, window_length=savgol_window, polyorder=savgol_order)\n",
    "        # No warnings\n",
    "\n",
    "        params = fit_sinusoidal(months_axis, smooth_trend)\n",
    "        fitted_curve = sinusoidal(months_axis, *params)\n",
    "\n",
    "        line, = ax.plot(months_axis, avg_trend, linestyle=\"-\", color=plot_color, linewidth=2.5, alpha=0.6, label=cluster_label_key)\n",
    "        ax.plot(months_axis, fitted_curve, linestyle=\"-\", color=\"black\", linewidth=1.2, alpha=0.9)\n",
    "\n",
    "\n",
    "    ax.set_xlabel(\"Time Step (e.g., Month)\", fontsize=15)\n",
    "    ax.set_ylabel(\"Cosine Similarity\", fontsize=15)\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    ax.legend(fontsize=12) # Fallback to default legend\n",
    "\n",
    "    ax.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path_svg:\n",
    "        # savefig will raise error on failure\n",
    "        plt.savefig(save_path_svg, format=\"svg\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_cluster_map(geopandas_map, clusters, cluster_colors, cluster_id_col='cluster_id', city_num_col='city_number', save_path_jpg=None):\n",
    "    \"\"\"Plots a map colored by cluster assignment.\"\"\"\n",
    "    # geopandas_map is the shapefile of the regions read using gpd\n",
    "    \n",
    "    if city_num_col not in geopandas_map.columns:\n",
    "        if city_num_col == 'city_number' and geopandas_map.index.name != city_num_col:\n",
    "            geopandas_map[city_num_col] = geopandas_map.index\n",
    "        else:\n",
    "            raise KeyError(f\"City identifier column '{city_num_col}' not found in shapefile.\")\n",
    "            \n",
    "    # Create dictionary mapping regions (cities) to clusters ---\n",
    "    city_to_cluster = {i: clusters[i] for i in range(len(clusters))}\n",
    "    \n",
    "\n",
    "    geopandas_map[cluster_id_col] = geopandas_map[city_num_col].map(city_to_cluster)\n",
    "\n",
    "\n",
    "    unmapped_count = geopandas_map[cluster_id_col].isna().sum()\n",
    "    if unmapped_count > 0:\n",
    "        geopandas_map[cluster_id_col] = geopandas_map[cluster_id_col].fillna(-1)\n",
    "    # No warning\n",
    "\n",
    "    # astype(int) might raise ValueError\n",
    "    geopandas_map[cluster_id_col] = geopandas_map[cluster_id_col].astype(int)\n",
    "    \n",
    "    \n",
    "    #assign color to each cluster\n",
    "    geopandas_map[\"color\"] = geopandas_map[cluster_id_col].map(cluster_colors).fillna('gray')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    geopandas_map.plot(ax=ax, color=geopandas_map[\"color\"], edgecolor=\"black\", linewidth=0.5, alpha=0.9)\n",
    "    #ax.legend(fontsize=12, title=\"Clusters\", loc='best')\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    plt.title(\"City Clusters\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path_jpg:\n",
    "        # savefig will raise error on failure\n",
    "        plt.savefig(save_path_jpg, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
